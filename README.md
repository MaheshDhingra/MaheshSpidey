# ğŸ•¸ï¸ GitHub Trending Scraper

A Python web scraper that fetches GitHub's trending repositories daily, respects `robots.txt`, and saves the data in a structured directory for analysis or public use.

---

## ğŸ¯ Objective

Track trending repositories on GitHub daily and store them in structured JSON files for further analysis or open data sharing.

---

## âš™ï¸ Setup

```bash
# Clone the repo
git clone https://github.com/yourusername/github-trending-scraper.git
cd github-trending-scraper

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### Run scraper once:

```bash
python scraper/github_scraper.py --today-only
```

### Print today's top trending repo:

```bash
python scraper/github_scraper.py --top
```

### Run scraper with daily scheduling (runs scraping at 10:00 AM daily):

```bash
python scraper/github_scraper.py
```

> *Note:* The scheduled run will keep the process running and scrape daily at 10:00 AM.

---

## ğŸ“ Directory Structure

```plaintext
github-trending-scraper/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 2025-07-02/
â”‚   â”‚   â”œâ”€â”€ trending.json     # Full list of trending repos for the day
â”‚   â”‚   â””â”€â”€ top.json          # Top starred repo for the day
â”‚   â”œâ”€â”€ 2025-07-03/
â”‚   â”‚   â”œâ”€â”€ trending.json
â”‚   â”‚   â””â”€â”€ top.json
â”‚   â””â”€â”€ tracked/              # Historical growth tracking per repo
â”‚       â”œâ”€â”€ microsoft_generative-ai-for-beginners.json
â”‚       â””â”€â”€ ...
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ scraper.log           # Log file for errors and events
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ github_scraper.py     # Main scraper script with CLI & scheduling support
â”œâ”€â”€ track_repo_growth.py      # Script to track repo star growth over time
â”œâ”€â”€ upload_to_kaggle.py       # Script to upload datasets to Kaggle
â”œâ”€â”€ daily_run.py              # Script to run scraper, tracker, and uploader sequentially
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This documentation
```

---

## ğŸ”’ Ethical Considerations

* Respects `robots.txt` before crawling
* Uses a custom, identifiable User-Agent header
* Handles errors and logs events for transparency

---

## ğŸ“¦ Additional Tools

* **`track_repo_growth.py`** â€” Tracks star growth for each repo over time
* **`upload_to_kaggle.py`** â€” Automates uploading daily datasets to Kaggle
* **`daily_run.py`** â€” Runs the scraper, tracker, and Kaggle uploader in sequence

---

## ğŸ’¡ Future Improvements

* Add notifications for trending repo changes
* Support scraping multiple GitHub trending languages or timeframes
* Integrate with dashboards or visualization tools

---

Feel free to contribute or open issues for bugs and feature requests!
Happy scraping! ğŸ•·ï¸âœ¨
